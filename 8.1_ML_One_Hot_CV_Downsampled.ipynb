{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold # for cross validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics # for f1 macro in cross validation\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from helper import util_visualizations, util_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train = pd.read_csv('/path/to/9_FINAL/data/machine_learning/one_hot_encoded/train/downsampled_training_data.csv', sep=\";\")\n",
    "del train['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10824, 65)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get variables\n",
    "X_train = train.copy()\n",
    "del X_train['label']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>class</th>\n",
       "      <th>frequency</th>\n",
       "      <th>pidspread</th>\n",
       "      <th>pldspread</th>\n",
       "      <th>id</th>\n",
       "      <th>pids</th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>...</th>\n",
       "      <th>p4</th>\n",
       "      <th>p42</th>\n",
       "      <th>p43</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8a</th>\n",
       "      <th>p8b</th>\n",
       "      <th>p8c</th>\n",
       "      <th>p8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>bacteria</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>472415879</td>\n",
       "      <td>['p1']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bee</td>\n",
       "      <td>insect</td>\n",
       "      <td>5163</td>\n",
       "      <td>40</td>\n",
       "      <td>2496</td>\n",
       "      <td>214216573</td>\n",
       "      <td>['p7p6p5p4p2p1p43p26p15ap25p24p20cp20bp20dp27a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dubai</td>\n",
       "      <td>camp</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199041901</td>\n",
       "      <td>['p8a', 'p8a']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>gruiformes</td>\n",
       "      <td>species</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>220552798</td>\n",
       "      <td>['p5']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>gabardine</td>\n",
       "      <td>material</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>411222195</td>\n",
       "      <td>['p5p10p8ap28bp20a', 'p5', 'p8b', 'p10', 'p3a'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10819</td>\n",
       "      <td>server</td>\n",
       "      <td>cosmetic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105572888</td>\n",
       "      <td>['p5']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10820</td>\n",
       "      <td>sturgeon</td>\n",
       "      <td>fish</td>\n",
       "      <td>657</td>\n",
       "      <td>28</td>\n",
       "      <td>413</td>\n",
       "      <td>377939019</td>\n",
       "      <td>['p5p4p2p1p10p8ap8cp23dp25p20bp28ap20dp20ap28b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10821</td>\n",
       "      <td>chocolatier</td>\n",
       "      <td>artisan</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>138575884</td>\n",
       "      <td>['p1', 'p1', 'p1', 'p1', 'p3a', 'p5', 'p1', 'p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10822</td>\n",
       "      <td>ballad</td>\n",
       "      <td>work</td>\n",
       "      <td>159</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>490515111</td>\n",
       "      <td>['p5p2p1p8ap3a', 'p23c', 'p8a', 'p8ap3a', 'p3a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10823</td>\n",
       "      <td>porcelain</td>\n",
       "      <td>invention</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>350948357</td>\n",
       "      <td>['p8a', 'p8b', 'p8b', 'p8a', 'p8a', 'p5']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10824 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          instance      class  frequency  pidspread  pldspread         id  \\\n",
       "0                a   bacteria          1          1          1  472415879   \n",
       "1              bee     insect       5163         40       2496  214216573   \n",
       "2            dubai       camp          2          1          1  199041901   \n",
       "3       gruiformes    species          1          1          1  220552798   \n",
       "4        gabardine   material         17          8         14  411222195   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "10819       server   cosmetic          1          1          1  105572888   \n",
       "10820     sturgeon       fish        657         28        413  377939019   \n",
       "10821  chocolatier    artisan         28          3         18  138575884   \n",
       "10822       ballad       work        159         19        128  490515111   \n",
       "10823    porcelain  invention          6          3          6  350948357   \n",
       "\n",
       "                                                    pids  p1  p10  p11  ...  \\\n",
       "0                                                 ['p1']   1    0    0  ...   \n",
       "1      ['p7p6p5p4p2p1p43p26p15ap25p24p20cp20bp20dp27a...   1    1    1  ...   \n",
       "2                                         ['p8a', 'p8a']   0    0    0  ...   \n",
       "3                                                 ['p5']   0    0    0  ...   \n",
       "4      ['p5p10p8ap28bp20a', 'p5', 'p8b', 'p10', 'p3a'...   0    1    0  ...   \n",
       "...                                                  ...  ..  ...  ...  ...   \n",
       "10819                                             ['p5']   0    0    0  ...   \n",
       "10820  ['p5p4p2p1p10p8ap8cp23dp25p20bp28ap20dp20ap28b...   1    1    0  ...   \n",
       "10821  ['p1', 'p1', 'p1', 'p1', 'p3a', 'p5', 'p1', 'p...   1    0    0  ...   \n",
       "10822  ['p5p2p1p8ap3a', 'p23c', 'p8a', 'p8ap3a', 'p3a...   1    1    0  ...   \n",
       "10823          ['p8a', 'p8b', 'p8b', 'p8a', 'p8a', 'p5']   0    0    0  ...   \n",
       "\n",
       "       p4  p42  p43  p5  p6  p7  p8a  p8b  p8c  p8d  \n",
       "0       0    0    0   0   0   0    0    0    0    0  \n",
       "1       1    0    1   1   1   1    1    1    1    1  \n",
       "2       0    0    0   0   0   0    1    0    0    0  \n",
       "3       0    0    0   1   0   0    0    0    0    0  \n",
       "4       0    0    0   1   0   0    1    1    1    0  \n",
       "...    ..  ...  ...  ..  ..  ..  ...  ...  ...  ...  \n",
       "10819   0    0    0   1   0   0    0    0    0    0  \n",
       "10820   1    0    1   1   1   0    1    1    1    1  \n",
       "10821   0    0    0   1   0   0    0    0    0    0  \n",
       "10822   1    0    1   1   0   0    1    1    0    0  \n",
       "10823   0    0    0   1   0   0    1    1    0    0  \n",
       "\n",
       "[10824 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12a</th>\n",
       "      <th>p12b</th>\n",
       "      <th>p12c</th>\n",
       "      <th>p13</th>\n",
       "      <th>p14</th>\n",
       "      <th>p15a</th>\n",
       "      <th>p15b</th>\n",
       "      <th>...</th>\n",
       "      <th>p4</th>\n",
       "      <th>p42</th>\n",
       "      <th>p43</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8a</th>\n",
       "      <th>p8b</th>\n",
       "      <th>p8c</th>\n",
       "      <th>p8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1  p10  p11  p12a  p12b  p12c  p13  p14  p15a  p15b  ...  p4  p42  p43  \\\n",
       "0   1    0    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "1   1    1    1     0     0     0    0    1     1     1  ...   1    0    1   \n",
       "2   0    0    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "3   0    0    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "4   0    1    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "\n",
       "   p5  p6  p7  p8a  p8b  p8c  p8d  \n",
       "0   0   0   0    0    0    0    0  \n",
       "1   1   1   1    1    1    1    1  \n",
       "2   0   0   0    1    0    0    0  \n",
       "3   1   0   0    0    0    0    0  \n",
       "4   1   0   0    1    1    1    0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take one hot encoded columns\n",
    "X_train_one_hot = X_train.drop(['instance', 'class', 'frequency', 'pidspread', 'pldspread', 'id', 'pids'], axis=1)\n",
    "X_train_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>pidspread</th>\n",
       "      <th>pldspread</th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12a</th>\n",
       "      <th>p12b</th>\n",
       "      <th>p12c</th>\n",
       "      <th>p13</th>\n",
       "      <th>...</th>\n",
       "      <th>p4</th>\n",
       "      <th>p42</th>\n",
       "      <th>p43</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8a</th>\n",
       "      <th>p8b</th>\n",
       "      <th>p8c</th>\n",
       "      <th>p8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5163</td>\n",
       "      <td>40</td>\n",
       "      <td>2496</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  pidspread  pldspread  p1  p10  p11  p12a  p12b  p12c  p13  ...  \\\n",
       "0          1          1          1   1    0    0     0     0     0    0  ...   \n",
       "1       5163         40       2496   1    1    1     0     0     0    0  ...   \n",
       "2          2          1          1   0    0    0     0     0     0    0  ...   \n",
       "3          1          1          1   0    0    0     0     0     0    0  ...   \n",
       "4         17          8         14   0    1    0     0     0     0    0  ...   \n",
       "\n",
       "   p4  p42  p43  p5  p6  p7  p8a  p8b  p8c  p8d  \n",
       "0   0    0    0   0   0   0    0    0    0    0  \n",
       "1   1    0    1   1   1   1    1    1    1    1  \n",
       "2   0    0    0   0   0   0    1    0    0    0  \n",
       "3   0    0    0   1   0   0    0    0    0    0  \n",
       "4   0    0    0   1   0   0    1    1    1    0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take one hot encoded columns\n",
    "X_train_one_hot_more = X_train.drop(['instance', 'class', 'id', 'pids'], axis=1) \n",
    "X_train_one_hot_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.139994</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.179872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1         2    3    4    5    6    7    8    9   ...   51   52  \\\n",
       "0  0.000000  0.00  0.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1  0.139994  0.78  0.179872  1.0  1.0  1.0  0.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "2  0.000027  0.00  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3  0.000000  0.00  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4  0.000434  0.14  0.000937  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "    53   54   55   56   57   58   59   60  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_one_hot_more_scaled = pd.DataFrame(min_max_scaler.fit_transform(X_train_one_hot_more))\n",
    "X_train_one_hot_more_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>pidspread</th>\n",
       "      <th>pldspread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5163</td>\n",
       "      <td>40</td>\n",
       "      <td>2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  pidspread  pldspread\n",
       "0          1          1          1\n",
       "1       5163         40       2496\n",
       "2          2          1          1\n",
       "3          1          1          1\n",
       "4         17          8         14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take one hot encoded columns\n",
    "X_train_one_hot_frequency = X_train[['frequency', 'pidspread', 'pldspread']]# TODO: frequency\n",
    "X_train_one_hot_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.139994</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.179872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1         2\n",
       "0  0.000000  0.00  0.000000\n",
       "1  0.139994  0.78  0.179872\n",
       "2  0.000027  0.00  0.000000\n",
       "3  0.000000  0.00  0.000000\n",
       "4  0.000434  0.14  0.000937"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_one_hot_frequency_scaled = pd.DataFrame(min_max_scaler.fit_transform(X_train_one_hot_frequency))\n",
    "X_train_one_hot_frequency_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test = pd.read_csv('/path/to/9_FINAL/data/machine_learning/one_hot_encoded/test/test_data.csv', sep=\";\")\n",
    "del test['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348121, 65)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get variables\n",
    "X_test = test.copy()\n",
    "del X_test['label']\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12a</th>\n",
       "      <th>p12b</th>\n",
       "      <th>p12c</th>\n",
       "      <th>p13</th>\n",
       "      <th>p14</th>\n",
       "      <th>p15a</th>\n",
       "      <th>p15b</th>\n",
       "      <th>...</th>\n",
       "      <th>p4</th>\n",
       "      <th>p42</th>\n",
       "      <th>p43</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8a</th>\n",
       "      <th>p8b</th>\n",
       "      <th>p8c</th>\n",
       "      <th>p8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1  p10  p11  p12a  p12b  p12c  p13  p14  p15a  p15b  ...  p4  p42  p43  \\\n",
       "0   0    0    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "1   0    0    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "2   0    0    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "3   1    1    0     0     0     0    0    0     0     0  ...   0    0    1   \n",
       "4   0    0    0     0     0     0    0    0     0     0  ...   0    0    0   \n",
       "\n",
       "   p5  p6  p7  p8a  p8b  p8c  p8d  \n",
       "0   0   0   0    0    0    0    0  \n",
       "1   0   0   0    0    0    0    0  \n",
       "2   0   0   0    1    0    1    0  \n",
       "3   1   0   0    1    0    0    0  \n",
       "4   1   0   0    1    0    0    0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take one hot encoded columns\n",
    "X_test_one_hot = X_test.drop(['instance', 'class', 'frequency', 'pidspread', 'pldspread', 'id', 'pids'], axis=1)\n",
    "X_test_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>pidspread</th>\n",
       "      <th>pldspread</th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12a</th>\n",
       "      <th>p12b</th>\n",
       "      <th>p12c</th>\n",
       "      <th>p13</th>\n",
       "      <th>...</th>\n",
       "      <th>p4</th>\n",
       "      <th>p42</th>\n",
       "      <th>p43</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8a</th>\n",
       "      <th>p8b</th>\n",
       "      <th>p8c</th>\n",
       "      <th>p8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  pidspread  pldspread  p1  p10  p11  p12a  p12b  p12c  p13  ...  \\\n",
       "0          3          2          2   0    0    0     0     0     0    0  ...   \n",
       "1          1          1          1   0    0    0     0     0     0    0  ...   \n",
       "2          2          2          2   0    0    0     0     0     0    0  ...   \n",
       "3        134         10         93   1    1    0     0     0     0    0  ...   \n",
       "4          3          2          3   0    0    0     0     0     0    0  ...   \n",
       "\n",
       "   p4  p42  p43  p5  p6  p7  p8a  p8b  p8c  p8d  \n",
       "0   0    0    0   0   0   0    0    0    0    0  \n",
       "1   0    0    0   0   0   0    0    0    0    0  \n",
       "2   0    0    0   0   0   0    1    0    1    0  \n",
       "3   0    0    1   1   0   0    1    0    0    0  \n",
       "4   0    0    0   1   0   0    1    0    0    0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take one hot encoded columns\n",
    "X_test_one_hot_more = X_test.drop(['instance', 'class',  'id', 'pids'], axis=1)\n",
    "X_test_one_hot_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2    3    4    5    6    7    8    9   ...   51  \\\n",
       "0  0.000031  0.020833  0.000132  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2  0.000015  0.020833  0.000132  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "3  0.002055  0.187500  0.012168  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "4  0.000031  0.020833  0.000265  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "    52   53   54   55   56   57   58   59   60  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "3  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_test_one_hot_more_scaled = pd.DataFrame(min_max_scaler.fit_transform(X_test_one_hot_more))\n",
    "X_test_one_hot_more_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>pidspread</th>\n",
       "      <th>pldspread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  pidspread  pldspread\n",
       "0          3          2          2\n",
       "1          1          1          1\n",
       "2          2          2          2\n",
       "3        134         10         93\n",
       "4          3          2          3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take one hot encoded columns\n",
    "X_test_one_hot_frequency = X_test[['frequency', 'pidspread', 'pldspread']]\n",
    "X_test_one_hot_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.012168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.000031  0.020833  0.000132\n",
       "1  0.000000  0.000000  0.000000\n",
       "2  0.000015  0.020833  0.000132\n",
       "3  0.002055  0.187500  0.012168\n",
       "4  0.000031  0.020833  0.000265"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_test_one_hot_frequency_scaled = pd.DataFrame(min_max_scaler.fit_transform(X_test_one_hot_frequency))\n",
    "X_test_one_hot_frequency_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Only one hot encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324 244 154]\n",
      " [ 80 501 140]\n",
      " [106 313 303]]\n",
      "Macro: 0.5162169229734085 || Micro: 0.5210161662817552\n",
      "[[314 230 177]\n",
      " [ 81 483 158]\n",
      " [115 344 263]]\n",
      "Macro: 0.4838802936285343 || Micro: 0.4896073903002309\n",
      "[[307 260 154]\n",
      " [ 79 511 132]\n",
      " [106 357 259]]\n",
      "Macro: 0.48915174291680197 || Micro: 0.497459584295612\n",
      "[[330 267 125]\n",
      " [ 90 490 142]\n",
      " [125 304 292]]\n",
      "Macro: 0.5089336648058641 || Micro: 0.5136258660508083\n",
      "[[316 257 149]\n",
      " [ 93 475 153]\n",
      " [123 315 283]]\n",
      "Macro: 0.49156731245234414 || Micro: 0.49630314232902034\n",
      "---------------------------\n",
      "Overall Macro: 0.49794998735539064 (+/- 0.012413106242158127) || Overall Micro: 0.5036024298514853 (+/- 0.011752299958773228)\n"
     ]
    }
   ],
   "source": [
    "# fit NB model\n",
    "nb = MultinomialNB()\n",
    "util_ml.get_cross_validated_confusion_matrix(nb, X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Only one hot encoded columns with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119 108 495]\n",
      " [ 12  34 675]\n",
      " [  2  17 703]]\n",
      "Macro: 0.29914882523644315 || Micro: 0.39538106235565823\n",
      "[[115 127 479]\n",
      " [  6  46 670]\n",
      " [  6   9 707]]\n",
      "Macro: 0.30716117532604276 || Micro: 0.4009237875288684\n",
      "[[120 127 474]\n",
      " [ 16  74 632]\n",
      " [  3  25 694]]\n",
      "Macro: 0.32851492351232875 || Micro: 0.4101616628175519\n",
      "[[126 139 457]\n",
      " [ 13  62 647]\n",
      " [  8  19 694]]\n",
      "Macro: 0.3242118728412895 || Micro: 0.40739030023094686\n",
      "[[125 120 477]\n",
      " [ 15  52 654]\n",
      " [  5  19 697]]\n",
      "Macro: 0.3164222839818463 || Micro: 0.40388170055452866\n",
      "---------------------------\n",
      "Overall Macro: 0.3150918161795901 (+/- 0.01079073132936679) || Overall Micro: 0.40354770269751084 (+/- 0.005141994245958679)\n"
     ]
    }
   ],
   "source": [
    "# fit NB model\n",
    "nb = MultinomialNB()\n",
    "util_ml.get_cross_validated_confusion_matrix(nb, X_train_one_hot_more, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Only with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108  98 516]\n",
      " [ 10  26 685]\n",
      " [  0  18 704]]\n",
      "Macro: 0.2844567913782739 || Micro: 0.3870669745958429\n",
      "[[ 98 126 497]\n",
      " [  6  38 678]\n",
      " [  3  10 709]]\n",
      "Macro: 0.2885551125492815 || Micro: 0.3903002309468822\n",
      "[[107 117 497]\n",
      " [ 15  43 664]\n",
      " [  4  12 706]]\n",
      "Macro: 0.29807920691772233 || Micro: 0.39538106235565823\n",
      "[[116 131 475]\n",
      " [ 12  43 667]\n",
      " [  6  22 693]]\n",
      "Macro: 0.3023211585737557 || Micro: 0.3935334872979215\n",
      "[[116 109 497]\n",
      " [ 10  35 676]\n",
      " [  5  16 700]]\n",
      "Macro: 0.2970478078166092 || Micro: 0.3932532347504621\n",
      "---------------------------\n",
      "Overall Macro: 0.29409201544712854 (+/- 0.0065703582476208024) || Overall Micro: 0.39190699798935336 (+/- 0.0029166580494660783)\n"
     ]
    }
   ],
   "source": [
    "# fit NB model\n",
    "nb = MultinomialNB()\n",
    "util_ml.get_cross_validated_confusion_matrix(nb, X_train_one_hot_frequency, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Scaled one hot encoded pids and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322 245 155]\n",
      " [ 79 501 141]\n",
      " [ 98 314 310]]\n",
      "Macro: 0.5189697584165969 || Micro: 0.523325635103926\n",
      "[[314 230 177]\n",
      " [ 81 482 159]\n",
      " [115 344 263]]\n",
      "Macro: 0.4835065892770982 || Micro: 0.48914549653579675\n",
      "[[307 260 154]\n",
      " [ 79 511 132]\n",
      " [106 357 259]]\n",
      "Macro: 0.48915174291680197 || Micro: 0.497459584295612\n",
      "[[329 268 125]\n",
      " [ 90 490 142]\n",
      " [124 304 293]]\n",
      "Macro: 0.5089801900732355 || Micro: 0.5136258660508083\n",
      "[[312 259 151]\n",
      " [ 90 478 153]\n",
      " [117 317 287]]\n",
      "Macro: 0.49297061850014945 || Micro: 0.49768946395563773\n",
      "---------------------------\n",
      "Overall Macro: 0.4987157798367764 (+/- 0.013201355417420313) || Overall Micro: 0.5042492091883561 (+/- 0.012402283009364232)\n"
     ]
    }
   ],
   "source": [
    "# fit NB model\n",
    "nb = MultinomialNB()\n",
    "util_ml.get_cross_validated_confusion_matrix(nb, X_train_one_hot_more_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Frequencies normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 85 213 424]\n",
      " [ 13 465 243]\n",
      " [  3 482 237]]\n",
      "Macro: 0.3308307129476383 || Micro: 0.36351039260969975\n",
      "[[206  67 448]\n",
      " [392  10 320]\n",
      " [445   5 272]]\n",
      "Macro: 0.189058593565974 || Micro: 0.22540415704387992\n",
      "[[220  68 433]\n",
      " [396  18 308]\n",
      " [429   0 293]]\n",
      "Macro: 0.20913935412559045 || Micro: 0.24526558891454966\n",
      "[[100  51 571]\n",
      " [ 16  11 695]\n",
      " [ 12   5 704]]\n",
      "Macro: 0.26213436035185866 || Micro: 0.3764434180138569\n",
      "[[ 87 206 429]\n",
      " [  8 380 333]\n",
      " [  5 424 292]]\n",
      "Macro: 0.32658182913072414 || Micro: 0.35073937153419593\n",
      "---------------------------\n",
      "Overall Macro: 0.2635489700243571 (+/- 0.058328719968135934) || Overall Micro: 0.31227258562323645 (+/- 0.06365369385129427)\n"
     ]
    }
   ],
   "source": [
    "# fit NB model\n",
    "nb = MultinomialNB()\n",
    "util_ml.get_cross_validated_confusion_matrix(nb, X_train_one_hot_frequency_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Only one hot encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[392 200 130]\n",
      " [113 456 152]\n",
      " [ 80 335 307]]\n",
      "Macro: 0.533634011055515 || Micro: 0.5334872979214781\n",
      "[[392 195 134]\n",
      " [114 436 172]\n",
      " [ 80 347 295]]\n",
      "Macro: 0.5195814381747486 || Micro: 0.5187066974595843\n",
      "[[382 206 133]\n",
      " [102 475 145]\n",
      " [ 79 363 280]]\n",
      "Macro: 0.5234848070570332 || Micro: 0.5251732101616629\n",
      "[[384 212 126]\n",
      " [ 88 483 151]\n",
      " [ 78 332 311]]\n",
      "Macro: 0.5437536935872119 || Micro: 0.5441108545034642\n",
      "[[362 208 152]\n",
      " [113 435 173]\n",
      " [ 96 336 289]]\n",
      "Macro: 0.501553878588028 || Micro: 0.5018484288354899\n",
      "---------------------------\n",
      "Overall Macro: 0.5244015656925073 (+/- 0.014183326712314622) || Overall Micro: 0.524665297776336 (+/- 0.014229053123652035)\n"
     ]
    }
   ],
   "source": [
    "# fit DT model\n",
    "dt = DecisionTreeClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(dt, X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Only one hot encoded columns with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[390 184 148]\n",
      " [116 421 184]\n",
      " [ 85 315 322]]\n",
      "Macro: 0.5250614763232201 || Micro: 0.523325635103926\n",
      "[[387 192 142]\n",
      " [129 416 177]\n",
      " [ 93 337 292]]\n",
      "Macro: 0.5063881981879659 || Micro: 0.5057736720554272\n",
      "[[388 190 143]\n",
      " [134 419 169]\n",
      " [107 314 301]]\n",
      "Macro: 0.5117245456013485 || Micro: 0.5117782909930716\n",
      "[[377 217 128]\n",
      " [119 453 150]\n",
      " [ 85 362 274]]\n",
      "Macro: 0.5085591468466265 || Micro: 0.5099307159353349\n",
      "[[390 198 134]\n",
      " [127 408 186]\n",
      " [110 312 299]]\n",
      "Macro: 0.5074464289496561 || Micro: 0.5069316081330869\n",
      "---------------------------\n",
      "Overall Macro: 0.5118359591817634 (+/- 0.006849967755087564) || Overall Micro: 0.5115479844441693 (+/- 0.006261553599670071)\n"
     ]
    }
   ],
   "source": [
    "# fit DT model\n",
    "dt = DecisionTreeClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(dt, X_train_one_hot_more, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Only with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[327 219 176]\n",
      " [112 253 356]\n",
      " [ 88 181 453]]\n",
      "Macro: 0.4742141460136881 || Micro: 0.4771362586605081\n",
      "[[348 177 196]\n",
      " [110 256 356]\n",
      " [ 76 218 428]]\n",
      "Macro: 0.47680847959746303 || Micro: 0.4766743648960739\n",
      "[[363 186 172]\n",
      " [116 234 372]\n",
      " [ 95 190 437]]\n",
      "Macro: 0.475060363609982 || Micro: 0.4775981524249423\n",
      "[[340 204 178]\n",
      " [106 246 370]\n",
      " [ 82 192 447]]\n",
      "Macro: 0.47522761109857886 || Micro: 0.4771362586605081\n",
      "[[355 172 195]\n",
      " [126 238 357]\n",
      " [ 83 205 433]]\n",
      "Macro: 0.4720023742377755 || Micro: 0.47412199630314233\n",
      "---------------------------\n",
      "Overall Macro: 0.4746625949114975 (+/- 0.0015722699998068814) || Overall Micro: 0.4765334061890349 (+/- 0.0012405896780541183)\n"
     ]
    }
   ],
   "source": [
    "# fit DT model\n",
    "dt = DecisionTreeClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(dt, X_train_one_hot_frequency, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Scaled one hot encoded pids and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[391 183 148]\n",
      " [116 421 184]\n",
      " [ 85 315 322]]\n",
      "Macro: 0.5255224219705296 || Micro: 0.5237875288683603\n",
      "[[386 192 143]\n",
      " [127 416 179]\n",
      " [ 92 337 293]]\n",
      "Macro: 0.5065323270604912 || Micro: 0.5057736720554272\n",
      "[[388 189 144]\n",
      " [135 418 169]\n",
      " [107 314 301]]\n",
      "Macro: 0.5112711543871202 || Micro: 0.5113163972286374\n",
      "[[377 217 128]\n",
      " [119 453 150]\n",
      " [ 85 361 275]]\n",
      "Macro: 0.5090680201522811 || Micro: 0.5103926096997691\n",
      "[[392 196 134]\n",
      " [127 408 186]\n",
      " [110 312 299]]\n",
      "Macro: 0.5083507845574983 || Micro: 0.5078558225508318\n",
      "---------------------------\n",
      "Overall Macro: 0.5121489416255841 (+/- 0.006856893179625532) || Overall Micro: 0.5118252060806052 (+/- 0.006289442820806848)\n"
     ]
    }
   ],
   "source": [
    "# fit DT model\n",
    "dt = DecisionTreeClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(dt, X_train_one_hot_more_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Frequencies normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325 221 176]\n",
      " [112 251 358]\n",
      " [ 88 181 453]]\n",
      "Macro: 0.47224740234366686 || Micro: 0.47528868360277143\n",
      "[[348 177 196]\n",
      " [109 257 356]\n",
      " [ 76 218 428]]\n",
      "Macro: 0.4773506304088979 || Micro: 0.4771362586605081\n",
      "[[364 186 171]\n",
      " [114 236 372]\n",
      " [ 95 191 436]]\n",
      "Macro: 0.4762647586253575 || Micro: 0.47852193995381065\n",
      "[[337 207 178]\n",
      " [104 247 371]\n",
      " [ 82 192 447]]\n",
      "Macro: 0.47438405664332084 || Micro: 0.4762124711316397\n",
      "[[353 172 197]\n",
      " [126 238 357]\n",
      " [ 80 208 433]]\n",
      "Macro: 0.4712156201094606 || Micro: 0.4731977818853974\n",
      "---------------------------\n",
      "Overall Macro: 0.47429249362614073 (+/- 0.0023194810879419232) || Overall Micro: 0.4760714270468254 (+/- 0.0017904913917507917)\n"
     ]
    }
   ],
   "source": [
    "# fit DT model\n",
    "dt = DecisionTreeClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(dt, X_train_one_hot_frequency_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Only one hot encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[462 153 107]\n",
      " [123 444 154]\n",
      " [ 83 312 327]]\n",
      "Macro: 0.5695900395779475 || Micro: 0.5695150115473441\n",
      "[[460 140 121]\n",
      " [112 421 189]\n",
      " [ 89 321 312]]\n",
      "Macro: 0.5516417504924891 || Micro: 0.5510392609699769\n",
      "[[458 136 127]\n",
      " [115 449 158]\n",
      " [ 82 329 311]]\n",
      "Macro: 0.5621748640956835 || Micro: 0.5625866050808314\n",
      "[[446 174 102]\n",
      " [110 461 151]\n",
      " [ 81 315 325]]\n",
      "Macro: 0.5693950974715651 || Micro: 0.5690531177829099\n",
      "[[438 187  97]\n",
      " [124 443 154]\n",
      " [ 98 328 295]]\n",
      "Macro: 0.5424086505347846 || Micro: 0.5434380776340111\n",
      "---------------------------\n",
      "Overall Macro: 0.559042080434494 (+/- 0.01058011919411825) || Overall Micro: 0.5591264146030147 (+/- 0.010295253968442023)\n"
     ]
    }
   ],
   "source": [
    "# fit random forest model\n",
    "rf = RandomForestClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(rf, X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Only one hot encoded columns with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[473 133 116]\n",
      " [141 400 180]\n",
      " [ 93 281 348]]\n",
      "Macro: 0.5642302918327688 || Micro: 0.563972286374134\n",
      "[[474 129 118]\n",
      " [132 416 174]\n",
      " [ 95 308 319]]\n",
      "Macro: 0.5578467632781211 || Micro: 0.5584295612009238\n",
      "[[477 133 111]\n",
      " [143 415 164]\n",
      " [ 98 300 324]]\n",
      "Macro: 0.5607200937179062 || Micro: 0.561662817551963\n",
      "[[468 152 102]\n",
      " [146 434 142]\n",
      " [ 96 307 318]]\n",
      "Macro: 0.5622685858261106 || Micro: 0.5635103926096998\n",
      "[[463 140 119]\n",
      " [138 385 198]\n",
      " [104 290 327]]\n",
      "Macro: 0.5431122558799722 || Micro: 0.5429759704251387\n",
      "---------------------------\n",
      "Overall Macro: 0.5576355981069758 (+/- 0.007555669843087196) || Overall Micro: 0.5581102056323719 (+/- 0.007814014649989896)\n"
     ]
    }
   ],
   "source": [
    "# fit random forest model\n",
    "rf = RandomForestClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(rf, X_train_one_hot_more, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Only with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[378 174 170]\n",
      " [107 255 359]\n",
      " [ 80 184 458]]\n",
      "Macro: 0.5019024632298744 || Micro: 0.5039260969976905\n",
      "[[379 146 196]\n",
      " [114 239 369]\n",
      " [ 74 220 428]]\n",
      "Macro: 0.48261522782080396 || Micro: 0.48314087759815244\n",
      "[[395 163 163]\n",
      " [119 232 371]\n",
      " [ 92 186 444]]\n",
      "Macro: 0.49126068431387404 || Micro: 0.49468822170900695\n",
      "[[384 161 177]\n",
      " [111 250 361]\n",
      " [ 86 184 451]]\n",
      "Macro: 0.49884838582596275 || Micro: 0.5011547344110855\n",
      "[[389 155 178]\n",
      " [129 232 360]\n",
      " [ 83 200 438]]\n",
      "Macro: 0.486334191376343 || Micro: 0.48937153419593343\n",
      "---------------------------\n",
      "Overall Macro: 0.4921921905133716 (+/- 0.007286925337509397) || Overall Micro: 0.49445629298237376 (+/- 0.007595965953456922)\n"
     ]
    }
   ],
   "source": [
    "# fit random forest model\n",
    "rf = RandomForestClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(rf, X_train_one_hot_frequency, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Scaled one hot encoded pids and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[474 133 115]\n",
      " [140 401 180]\n",
      " [ 93 281 348]]\n",
      "Macro: 0.5651421687542882 || Micro: 0.5648960739030023\n",
      "[[473 130 118]\n",
      " [131 416 175]\n",
      " [ 95 306 321]]\n",
      "Macro: 0.5584418953134768 || Micro: 0.558891454965358\n",
      "[[475 134 112]\n",
      " [144 414 164]\n",
      " [100 300 322]]\n",
      "Macro: 0.558329848377619 || Micro: 0.5593533487297921\n",
      "[[466 153 103]\n",
      " [145 434 143]\n",
      " [ 96 307 318]]\n",
      "Macro: 0.5614248952703076 || Micro: 0.5625866050808314\n",
      "[[459 143 120]\n",
      " [136 385 200]\n",
      " [103 290 328]]\n",
      "Macro: 0.5419952147055084 || Micro: 0.5415896487985212\n",
      "---------------------------\n",
      "Overall Macro: 0.55706680448424 (+/- 0.007935281173559001) || Overall Micro: 0.557463426295501 (+/- 0.00823503607808668)\n"
     ]
    }
   ],
   "source": [
    "# fit random forest model\n",
    "rf = RandomForestClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(rf, X_train_one_hot_more_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Frequencies normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[380 171 171]\n",
      " [108 255 358]\n",
      " [ 81 183 458]]\n",
      "Macro: 0.5027118468581019 || Micro: 0.5048498845265589\n",
      "[[380 146 195]\n",
      " [112 242 368]\n",
      " [ 74 220 428]]\n",
      "Macro: 0.4847128264586094 || Micro: 0.48498845265588914\n",
      "[[394 164 163]\n",
      " [118 233 371]\n",
      " [ 94 186 442]]\n",
      "Macro: 0.49050708532017745 || Micro: 0.49376443418013855\n",
      "[[382 162 178]\n",
      " [111 249 362]\n",
      " [ 87 183 451]]\n",
      "Macro: 0.49735938876584423 || Micro: 0.4997690531177829\n",
      "[[388 156 178]\n",
      " [129 235 357]\n",
      " [ 83 201 437]]\n",
      "Macro: 0.48706387926212313 || Micro: 0.4898336414048059\n",
      "---------------------------\n",
      "Overall Macro: 0.4924710053329712 (+/- 0.00666414977831259) || Overall Micro: 0.4946410931770351 (+/- 0.007036604103424382)\n"
     ]
    }
   ],
   "source": [
    "# fit random forest model\n",
    "rf = RandomForestClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(rf, X_train_one_hot_frequency_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Only one hot encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[409 186 127]\n",
      " [ 90 481 150]\n",
      " [ 74 320 328]]\n",
      "Macro: 0.5630800785025155 || Micro: 0.5625866050808314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[438 150 133]\n",
      " [109 414 199]\n",
      " [ 82 311 329]]\n",
      "Macro: 0.5477127732921337 || Micro: 0.5454965357967667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[397 166 158]\n",
      " [ 96 438 188]\n",
      " [ 72 310 340]]\n",
      "Macro: 0.5452750732234604 || Micro: 0.5427251732101617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[400 206 116]\n",
      " [ 99 482 141]\n",
      " [ 74 313 334]]\n",
      "Macro: 0.5621320740458517 || Micro: 0.561662817551963\n",
      "[[399 187 136]\n",
      " [100 451 170]\n",
      " [ 82 323 316]]\n",
      "Macro: 0.5397624773844881 || Micro: 0.5388170055452866\n",
      "---------------------------\n",
      "Overall Macro: 0.5515924952896899 (+/- 0.00935904563946058) || Overall Micro: 0.5502576274370019 (+/- 0.009923464524608431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit nnet\n",
    "nnet = MLPClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(nnet, X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Only one hot encoded columns with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[501 133  88]\n",
      " [145 444 132]\n",
      " [112 299 311]]\n",
      "Macro: 0.5764927420592897 || Micro: 0.5801385681293303\n",
      "[[456 122 143]\n",
      " [118 409 195]\n",
      " [ 77 307 338]]\n",
      "Macro: 0.5575433106789855 || Micro: 0.5556581986143188\n",
      "[[257 318 146]\n",
      " [ 44 533 145]\n",
      " [ 21 372 329]]\n",
      "Macro: 0.5103980497919498 || Micro: 0.5168591224018476\n",
      "[[513 120  89]\n",
      " [160 430 132]\n",
      " [116 290 315]]\n",
      "Macro: 0.5769300060052878 || Micro: 0.5810623556581986\n",
      "[[466 138 118]\n",
      " [144 407 170]\n",
      " [ 88 294 339]]\n",
      "Macro: 0.560366753004777 || Micro: 0.5600739371534196\n",
      "---------------------------\n",
      "Overall Macro: 0.5563461723080578 (+/- 0.024324500630392067) || Overall Micro: 0.558758436391423 (+/- 0.023330106631198843)\n"
     ]
    }
   ],
   "source": [
    "# fit nnet\n",
    "nnet = MLPClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(nnet, X_train_one_hot_more, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Only with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[474 125 123]\n",
      " [151 219 351]\n",
      " [143 154 425]]\n",
      "Macro: 0.5066400651986128 || Micro: 0.5163972286374134\n",
      "[[412 149 160]\n",
      " [102 231 389]\n",
      " [ 78 221 423]]\n",
      "Macro: 0.4920621599289466 || Micro: 0.492378752886836\n",
      "[[452 102 167]\n",
      " [133 202 387]\n",
      " [ 92 153 477]]\n",
      "Macro: 0.5111704180552583 || Micro: 0.5224018475750577\n",
      "[[489  44 189]\n",
      " [203  74 445]\n",
      " [144  82 495]]\n",
      "Macro: 0.4411278662454457 || Micro: 0.4886836027713626\n",
      "[[404  26 292]\n",
      " [133  49 539]\n",
      " [ 68  37 616]]\n",
      "Macro: 0.431601659870493 || Micro: 0.493992606284658\n",
      "---------------------------\n",
      "Overall Macro: 0.47652043385975124 (+/- 0.033525181416299545) || Overall Micro: 0.5027708076310655 (+/- 0.013817076681912333)\n"
     ]
    }
   ],
   "source": [
    "# fit nnet\n",
    "nnet = MLPClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(nnet, X_train_one_hot_frequency, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Scaled one hot encoded pids and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[434 187 101]\n",
      " [112 463 146]\n",
      " [ 82 313 327]]\n",
      "Macro: 0.5658246092489957 || Micro: 0.5653579676674365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[417 174 130]\n",
      " [100 445 177]\n",
      " [ 81 320 321]]\n",
      "Macro: 0.5478915148333582 || Micro: 0.5464203233256351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[413 169 139]\n",
      " [110 444 168]\n",
      " [ 80 320 322]]\n",
      "Macro: 0.5457022995163032 || Micro: 0.5445727482678984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[409 193 120]\n",
      " [105 473 144]\n",
      " [ 83 307 331]]\n",
      "Macro: 0.5604394670327036 || Micro: 0.5602771362586605\n",
      "[[405 188 129]\n",
      " [105 435 181]\n",
      " [ 86 320 315]]\n",
      "Macro: 0.5351525189481875 || Micro: 0.5337338262476895\n",
      "---------------------------\n",
      "Overall Macro: 0.5510020819159097 (+/- 0.010933833012340986) || Overall Micro: 0.550072400353464 (+/- 0.011386992987563824)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit nnet\n",
    "nnet = MLPClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(nnet, X_train_one_hot_more_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Frequencies normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478  64 180]\n",
      " [146  57 518]\n",
      " [134  54 534]]\n",
      "Macro: 0.43991640831136736 || Micro: 0.49376443418013855\n",
      "[[470 126 125]\n",
      " [154 183 385]\n",
      " [112 167 443]]\n",
      "Macro: 0.4932085653910425 || Micro: 0.5062355658198614\n",
      "[[433 152 136]\n",
      " [120 217 385]\n",
      " [ 84 212 426]]\n",
      "Macro: 0.4937551125545528 || Micro: 0.4969976905311778\n",
      "[[470 121 131]\n",
      " [163 186 373]\n",
      " [115 176 430]]\n",
      "Macro: 0.48926897916487766 || Micro: 0.5016166281755197\n",
      "[[475  58 189]\n",
      " [174  74 473]\n",
      " [137  63 521]]\n",
      "Macro: 0.44627147825527763 || Micro: 0.4944547134935305\n",
      "---------------------------\n",
      "Overall Macro: 0.47248410873542357 (+/- 0.02413067628591187) || Overall Micro: 0.4986138064400456 (+/- 0.004701796475872791)\n"
     ]
    }
   ],
   "source": [
    "# fit nnet\n",
    "nnet = MLPClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(nnet, X_train_one_hot_frequency_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Only one hot encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[456 152 114]\n",
      " [110 457 154]\n",
      " [ 88 283 351]]\n",
      "Macro: 0.5843088772667501 || Micro: 0.5838337182448037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[447 152 122]\n",
      " [124 438 160]\n",
      " [ 91 325 306]]\n",
      "Macro: 0.5495738752972253 || Micro: 0.5501154734411086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[446 156 119]\n",
      " [125 448 149]\n",
      " [ 87 321 314]]\n",
      "Macro: 0.5574866871788088 || Micro: 0.5579676674364896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[420 194 108]\n",
      " [100 473 149]\n",
      " [ 55 316 350]]\n",
      "Macro: 0.5765318542806038 || Micro: 0.5741339491916859\n",
      "[[455 170  97]\n",
      " [138 420 163]\n",
      " [ 89 298 334]]\n",
      "Macro: 0.5593987774782433 || Micro: 0.5586876155268022\n",
      "---------------------------\n",
      "Overall Macro: 0.5654600143003263 (+/- 0.012888345318944868) || Overall Micro: 0.564947684768178 (+/- 0.012239063005370705)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# fit LogReg\n",
    "log_reg = LogisticRegression(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(log_reg, X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Only one hot encoded columns with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[406 226  90]\n",
      " [ 69 519 133]\n",
      " [ 55 378 289]]\n",
      "Macro: 0.559954828914633 || Micro: 0.5607390300230947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[391 245  85]\n",
      " [ 75 519 128]\n",
      " [ 61 411 250]]\n",
      "Macro: 0.531907749961489 || Micro: 0.535796766743649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[364 235 122]\n",
      " [ 74 518 130]\n",
      " [ 39 404 279]]\n",
      "Macro: 0.5347892585756789 || Micro: 0.5362586605080831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[381 249  92]\n",
      " [ 81 521 120]\n",
      " [ 62 383 276]]\n",
      "Macro: 0.5412886660196555 || Micro: 0.5441108545034642\n",
      "[[375 206 141]\n",
      " [ 86 444 191]\n",
      " [ 56 314 351]]\n",
      "Macro: 0.5441099479574559 || Micro: 0.5406654343807763\n",
      "---------------------------\n",
      "Overall Macro: 0.5424100902857825 (+/- 0.009801440611300815) || Overall Micro: 0.5435141492318134 (+/- 0.009136387260251065)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# fit LogReg\n",
    "log_reg = LogisticRegression(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(log_reg, X_train_one_hot_more, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Only with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[413 309   0]\n",
      " [ 85 636   0]\n",
      " [ 78 644   0]]\n",
      "Macro: 0.3956709956709957 || Micro: 0.48452655889145496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[403 318   0]\n",
      " [ 99 623   0]\n",
      " [ 74 648   0]]\n",
      "Macro: 0.3868648717357601 || Micro: 0.47390300230946886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402 184 135]\n",
      " [ 94 250 378]\n",
      " [ 59 249 414]]\n",
      "Macro: 0.49602947616402454 || Micro: 0.492378752886836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[394 328   0]\n",
      " [102 620   0]\n",
      " [ 74 647   0]]\n",
      "Macro: 0.38169397191218674 || Micro: 0.46836027713625866\n",
      "[[393 223 106]\n",
      " [109 321 291]\n",
      " [ 79 284 358]]\n",
      "Macro: 0.5009263747557401 || Micro: 0.4953789279112754\n",
      "---------------------------\n",
      "Overall Macro: 0.43223713804774144 (+/- 0.05429182370021794) || Overall Micro: 0.48290950382705883 (+/- 0.010397741569360757)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# fit LogReg\n",
    "log_reg = LogisticRegression(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(log_reg, X_train_one_hot_frequency, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Scaled one hot encoded pids and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[456 152 114]\n",
      " [111 456 154]\n",
      " [ 89 282 351]]\n",
      "Macro: 0.5838088925450436 || Micro: 0.5833718244803695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[447 152 122]\n",
      " [124 438 160]\n",
      " [ 91 325 306]]\n",
      "Macro: 0.5495738752972253 || Micro: 0.5501154734411086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[446 156 119]\n",
      " [126 448 148]\n",
      " [ 87 321 314]]\n",
      "Macro: 0.5574536459043163 || Micro: 0.5579676674364896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[424 190 108]\n",
      " [104 469 149]\n",
      " [ 57 314 350]]\n",
      "Macro: 0.5764382807199122 || Micro: 0.5741339491916859\n",
      "[[454 170  98]\n",
      " [138 420 163]\n",
      " [ 89 298 334]]\n",
      "Macro: 0.558948927341896 || Micro: 0.5582255083179297\n",
      "---------------------------\n",
      "Overall Macro: 0.5652447243616787 (+/- 0.012773703600202782) || Overall Micro: 0.5647628845735166 (+/- 0.012145521097614666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# fit LogReg\n",
    "log_reg = LogisticRegression(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(log_reg, X_train_one_hot_more_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Frequencies normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[413 129 180]\n",
      " [ 85 117 519]\n",
      " [ 78 110 534]]\n",
      "Macro: 0.4666417971506703 || Micro: 0.4914549653579677\n",
      "[[403 129 189]\n",
      " [ 99 114 509]\n",
      " [ 74  81 567]]\n",
      "Macro: 0.47003897416056745 || Micro: 0.5006928406466513\n",
      "[[402 109 210]\n",
      " [ 94 117 511]\n",
      " [ 59 140 523]]\n",
      "Macro: 0.4590707780782742 || Micro: 0.4812933025404157\n",
      "[[395 118 209]\n",
      " [102 122 498]\n",
      " [ 74 107 540]]\n",
      "Macro: 0.4626711337684785 || Micro: 0.4882217090069284\n",
      "[[393 140 189]\n",
      " [109 135 477]\n",
      " [ 79 119 523]]\n",
      "Macro: 0.4643399254001463 || Micro: 0.4856746765249538\n",
      "---------------------------\n",
      "Overall Macro: 0.46455252171162736 (+/- 0.003690543683002763) || Overall Micro: 0.4894674988153834 (+/- 0.0065224734633731)\n"
     ]
    }
   ],
   "source": [
    "# fit LogReg\n",
    "log_reg = LogisticRegression(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(log_reg, X_train_one_hot_frequency_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Only one hot encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[459 150 113]\n",
      " [126 435 160]\n",
      " [ 93 284 345]]\n",
      "Macro: 0.572603156723123 || Micro: 0.5722863741339492\n",
      "[[453 153 115]\n",
      " [119 437 166]\n",
      " [ 93 320 309]]\n",
      "Macro: 0.5534184849105941 || Micro: 0.553810623556582\n",
      "[[441 154 126]\n",
      " [107 470 145]\n",
      " [ 66 336 320]]\n",
      "Macro: 0.5689886726024831 || Micro: 0.5685912240184757\n",
      "[[427 187 108]\n",
      " [103 472 147]\n",
      " [ 69 302 350]]\n",
      "Macro: 0.5784288525527338 || Micro: 0.576905311778291\n",
      "[[427 186 109]\n",
      " [116 440 165]\n",
      " [ 75 312 334]]\n",
      "Macro: 0.5567956720045663 || Micro: 0.5549907578558225\n",
      "---------------------------\n",
      "Overall Macro: 0.5660469677587001 (+/- 0.009486973852111563) || Overall Micro: 0.5653168582686241 (+/- 0.009301716660814766)\n"
     ]
    }
   ],
   "source": [
    "# fit xgboost\n",
    "xg = xgb.XGBClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(xg, X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Only one hot encoded columns with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[461 134 127]\n",
      " [108 431 182]\n",
      " [ 69 273 380]]\n",
      "Macro: 0.5898282675280982 || Micro: 0.5875288683602772\n",
      "[[456 145 120]\n",
      " [107 438 177]\n",
      " [ 66 312 344]]\n",
      "Macro: 0.5740228060068747 || Micro: 0.571824480369515\n",
      "[[453 140 128]\n",
      " [125 430 167]\n",
      " [ 88 310 324]]\n",
      "Macro: 0.5577529345598373 || Micro: 0.5575057736720554\n",
      "[[430 184 108]\n",
      " [108 471 143]\n",
      " [ 75 317 329]]\n",
      "Macro: 0.5686799454059495 || Micro: 0.5681293302540416\n",
      "[[439 163 120]\n",
      " [126 423 172]\n",
      " [ 85 311 325]]\n",
      "Macro: 0.5495363766521737 || Micro: 0.5485212569316081\n",
      "---------------------------\n",
      "Overall Macro: 0.5679640660305867 (+/- 0.013849989619088747) || Overall Micro: 0.5667019419174995 (+/- 0.013244965229575165)\n"
     ]
    }
   ],
   "source": [
    "# fit xgboost\n",
    "xg = xgb.XGBClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(xg, X_train_one_hot_more, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Only with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415 155 152]\n",
      " [110 267 344]\n",
      " [ 83 198 441]]\n",
      "Macro: 0.5179720036079778 || Micro: 0.5187066974595843\n",
      "[[410 144 167]\n",
      " [121 253 348]\n",
      " [ 84 223 415]]\n",
      "Macro: 0.4977476476412474 || Micro: 0.49792147806004616\n",
      "[[415 155 151]\n",
      " [112 258 352]\n",
      " [ 80 199 443]]\n",
      "Macro: 0.5143272188845626 || Micro: 0.515473441108545\n",
      "[[405 158 159]\n",
      " [109 252 361]\n",
      " [ 83 192 446]]\n",
      "Macro: 0.5078385012409767 || Micro: 0.5094688221709007\n",
      "[[400 138 184]\n",
      " [129 233 359]\n",
      " [100 190 431]]\n",
      "Macro: 0.48806769069419514 || Micro: 0.49168207024029575\n",
      "---------------------------\n",
      "Overall Macro: 0.5051906124137919 (+/- 0.010976748395790515) || Overall Micro: 0.5066505018078744 (+/- 0.010309110925271)\n"
     ]
    }
   ],
   "source": [
    "# fit xgboost\n",
    "xg = xgb.XGBClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(xg, X_train_one_hot_frequency, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Scaled one hot encoded pids and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[462 134 126]\n",
      " [108 431 182]\n",
      " [ 70 273 379]]\n",
      "Macro: 0.5897676086885398 || Micro: 0.5875288683602772\n",
      "[[455 146 120]\n",
      " [107 438 177]\n",
      " [ 66 312 344]]\n",
      "Macro: 0.5735839325281199 || Micro: 0.5713625866050809\n",
      "[[453 140 128]\n",
      " [125 430 167]\n",
      " [ 88 310 324]]\n",
      "Macro: 0.5577529345598373 || Micro: 0.5575057736720554\n",
      "[[430 184 108]\n",
      " [108 471 143]\n",
      " [ 75 317 329]]\n",
      "Macro: 0.5686799454059495 || Micro: 0.5681293302540416\n",
      "[[439 163 120]\n",
      " [126 423 172]\n",
      " [ 85 311 325]]\n",
      "Macro: 0.5495363766521737 || Micro: 0.5485212569316081\n",
      "---------------------------\n",
      "Overall Macro: 0.567864159566924 (+/- 0.013793381676732821) || Overall Micro: 0.5666095631646126 (+/- 0.013210481135862186)\n"
     ]
    }
   ],
   "source": [
    "# fit xgboost\n",
    "xg = xgb.XGBClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(xg, X_train_one_hot_more_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Frequencies normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415 155 152]\n",
      " [110 267 344]\n",
      " [ 84 198 440]]\n",
      "Macro: 0.5175205091083818 || Micro: 0.5182448036951501\n",
      "[[410 144 167]\n",
      " [121 253 348]\n",
      " [ 84 223 415]]\n",
      "Macro: 0.4977476476412474 || Micro: 0.49792147806004616\n",
      "[[415 155 151]\n",
      " [112 258 352]\n",
      " [ 80 199 443]]\n",
      "Macro: 0.5143272188845626 || Micro: 0.515473441108545\n",
      "[[405 158 159]\n",
      " [109 252 361]\n",
      " [ 83 192 446]]\n",
      "Macro: 0.5078385012409767 || Micro: 0.5094688221709007\n",
      "[[401 138 183]\n",
      " [129 233 359]\n",
      " [100 190 431]]\n",
      "Macro: 0.48851486254527837 || Micro: 0.4921441774491682\n",
      "---------------------------\n",
      "Overall Macro: 0.5051897478840893 (+/- 0.010733066664170366) || Overall Micro: 0.5066505444967621 (+/- 0.010068210623604195)\n"
     ]
    }
   ],
   "source": [
    "# fit xgboost\n",
    "xg = xgb.XGBClassifier(random_state=88)\n",
    "util_ml.get_cross_validated_confusion_matrix(xg, X_train_one_hot_frequency_scaled, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
